Изначально датасет разбивается на тренировочный и тестовый. Далее с помощью k-fold кросс-валидации тренировочный датасет разбивается на k фолдов. Базовая модель обучается на k-1 фолдах и делает прогноз на оставшемся. Данная процедура повторяется для каждого фолда и в итоге получится вектор, состоящий из k-fold прогнозов и используемый как новый признак. Предыдущие шаги повторяются для каждой базовой модели и в итоге получится набор признаков, состоящий из прогнозов базовых моделей, к которым добавляется таргет _y_train_ из исходного тренировочного датасета и полученный датасет будет новым тренировочным. 

Помимо этого, базовые модели также обучаются на всём исходном тренировочном множестве, после чего делается прогноз на тестовом датасете и в итоге получится новый тестовый набор.
На полученных датасетах (метаданных) обучается метамодель и производится итоговый прогноз
![[Pasted image 20250212181555.png]]




# Дальше идёт сомнительная информация (такая же, но всё таки так себе)



# Первая картинка не стекинг, просто идея как можно сделать композицию моделей нелинейной
![[Pasted image 20250207133841.png]]
# Но здесь базовые модели нельзя обучать на одних и тех же данные, т.к будет возникать переобучение

![[Pasted image 20250207133931.png]]
# То есть делим выборку на k блоков, и каждую модель обучаем k раз. Каждый раз на всех кроме одного блока k. И для каждого такого блока будем считать функционал с ошибкой на метамодели полученной из базовых обученных на всех блоках кроме k-ого.
![[Pasted image 20250207134014.png]]





