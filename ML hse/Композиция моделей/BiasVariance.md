	# Взяли выборку X и выкинули 10% оттуда, потом выкинули другие 10%. Но результаты получились совсем разные - нужно как то исправлять
![[Pasted image 20250205212851.png]]
# #Bootstrap

![[Pasted image 20250205213307.png]]
![[Pasted image 20250205215202.png]]
![[Pasted image 20250205215222.png]]
# Введём ошибку метода обучения L($\mu$). Внешнее матожидание идёт по всем выборкам, а внутреннее по всем элементам текущей выборки. 

### Что даёт этот функционал: для каждой **выборки** мы строим модель, и смотрим среднюю ошибку на этой **ней**. --> Т.е суммарная ошибка по всем выборкам для модели. 

![[Pasted image 20250205215236.png]]
# Первое слагаемое #шум  показывает насколько мы вообще способны решить задачу
# Второе слагаемое показывает #смещение - средняя модель по всем выборкам отклоняется от ЛУЧШЕЙ( E(y|x) ) и берём среднее по всем тестовым объектам - ((Т.Е насколько вообще подходит семейство моделей для данной задачи))

# Третье слагаемое показывает насколько модели отличаются от средней модели в зависимости от выборки. ((Т.е если мы немного поменяет нашу модель, насколько изменятся её результаты - чувствительная модель и склонная к переобучению))

![[Pasted image 20250205215313.png]]

# #ВысокоеСмещениеПлохо
# #ВысокийРазбросПлохо



![[Pasted image 20250205230835.png]]
![[Pasted image 20250205231540.png]]
# Здесь для каждой подвыборки поделим её на N частей b(x) и усредняя, получим a(x). Получается для каждой подвыборки исходной выборки получим разные функции a(x)
![[Pasted image 20250205231553.png]]
![[Pasted image 20250212221903.png]]
